{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3816,"databundleVersionId":32105,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install dagshub mlflow neuralforecast --quiet\n\nimport warnings\nfrom statsmodels.tools.sm_exceptions import ValueWarning\n\nwarnings.filterwarnings(\"ignore\", category=ValueWarning)\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:56:13.882473Z","iopub.execute_input":"2025-07-05T10:56:13.882755Z","iopub.status.idle":"2025-07-05T10:57:38.441473Z","shell.execute_reply.started":"2025-07-05T10:56:13.882730Z","shell.execute_reply":"2025-07-05T10:57:38.440035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:57:47.521399Z","iopub.execute_input":"2025-07-05T10:57:47.521980Z","iopub.status.idle":"2025-07-05T10:57:47.528105Z","shell.execute_reply.started":"2025-07-05T10:57:47.521948Z","shell.execute_reply":"2025-07-05T10:57:47.527384Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, FunctionTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nimport mlflow\nimport mlflow.sklearn\nimport dagshub\nimport joblib\nimport os\nfrom sklearn.model_selection import GridSearchCV\nfrom tqdm import tqdm\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import TFT\n\npd.set_option(\"display.max_rows\", 100) \n\ndagshub.init(repo_owner='gnada22', repo_name='ml_final_project', mlflow=True)\n\nmlflow.set_experiment(\"TFT_Training\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:58:23.897425Z","iopub.execute_input":"2025-07-05T10:58:23.898154Z","iopub.status.idle":"2025-07-05T10:58:24.274445Z","shell.execute_reply.started":"2025-07-05T10:58:23.898128Z","shell.execute_reply":"2025-07-05T10:58:24.273604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DateFeatureCreator(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        X = X.copy()\n        X[\"week\"] = (\n            X[\"Date\"].dt.to_period(\"W\")\n            .rank(method=\"dense\")\n            .astype(int) - 1\n        )\n        X[\"sin_13\"] = np.sin(2 * np.pi * X[\"week\"] / 13)\n        X[\"cos_13\"] = np.cos(2 * np.pi * X[\"week\"] / 13)\n        X[\"sin_23\"] = np.sin(2 * np.pi * X[\"week\"] / 23)\n        X[\"cos_23\"] = np.cos(2 * np.pi * X[\"week\"] / 23)\n        X = X.drop(columns=[\"Date\"])\n        return X\n\ndate_features = [\"week\", \"sin_13\", \"cos_13\", \"sin_23\", \"cos_23\"]\nlag_features = []\nadded_features = date_features + lag_features\n\nclass ColumnDropper(BaseEstimator, TransformerMixin):\n    def __init__(self, columns):\n        self.columns = columns\n\n    def fit(self, X, y=None):\n        return self\n        \n    def transform(self, X):\n        return X.drop(columns=self.columns, errors=\"ignore\")\n\nclass ColumnTransformerWithNames(ColumnTransformer):\n    def get_feature_names_out(self, input_features=None):\n        return super().get_feature_names_out(input_features)\n\n    def transform(self, X):\n        X_transformed = super().transform(X)\n        cols = self.get_feature_names_out()\n        cols = [c.split(\"__\", 1)[-1] for c in self.get_feature_names_out()]\n        res = pd.DataFrame(X_transformed, columns=cols, index=X.index)\n        return res\n\n    def fit_transform(self, X, y=None):\n        X_transformed = super().fit_transform(X, y)\n        cols = self.get_feature_names_out()\n        cols = [c.split(\"__\", 1)[-1] for c in self.get_feature_names_out()]\n        res = pd.DataFrame(X_transformed, columns=cols, index=X.index)\n        return res\n\nclass MultiIndexKeeper(BaseEstimator, TransformerMixin):\n    def __init__(self, index_cols=[\"Date\", \"Store\", \"Dept\"]):\n        self.index_cols = index_cols\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        X = X.copy()\n        X.set_index(self.index_cols, drop=False, inplace=True)\n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:58:26.205547Z","iopub.execute_input":"2025-07-05T10:58:26.205876Z","iopub.status.idle":"2025-07-05T10:58:26.216006Z","shell.execute_reply.started":"2025-07-05T10:58:26.205850Z","shell.execute_reply":"2025-07-05T10:58:26.215255Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TFTRegressor(BaseEstimator, RegressorMixin):\n    def __init__(self, input_chunk_length=52, output_chunk_length=39, epochs=10, batch_size=32):\n        self.input_chunk_length = input_chunk_length\n        self.output_chunk_length = output_chunk_length\n        self.epochs = epochs\n        self.batch_size = batch_size\n\n    def fit(self, X, y):\n        df = X.copy()\n        df[\"y\"] = y.values\n\n        if not isinstance(df.index, pd.MultiIndex):\n            raise ValueError(\"X must have a MultiIndex\")\n\n        df = df.reset_index()\n        df.rename(columns={\"Date\": \"ds\"}, inplace=True)\n        df[\"unique_id\"] = df[\"Store\"].astype(str) + \"_\" + df[\"Dept\"].astype(str)\n\n        self.train_df_ = df[[\"unique_id\", \"ds\", \"y\"]].copy()\n\n        model = TFT(\n            input_size=self.input_chunk_length,\n            h=self.output_chunk_length,\n            max_steps=self.epochs * 104,\n            batch_size=self.batch_size,\n            random_seed=42\n        )\n\n        self.nf_ = NeuralForecast(models=[model], freq=\"W-FRI\")\n        self.nf_.fit(df=self.train_df_)\n        return self\n\n    def predict(self, X):\n        df = X.reset_index()\n        df.rename(columns={\"Date\": \"ds\"}, inplace=True)\n        df[\"unique_id\"] = df[\"Store\"].astype(str) + \"_\" + df[\"Dept\"].astype(str)\n\n        forecast_df = self.nf_.predict()\n        forecast_df = forecast_df.rename(columns={\"TFT\": \"y_hat\"})\n\n        merged = df.merge(forecast_df, on=[\"unique_id\", \"ds\"], how=\"left\")\n        preds = pd.Series(data=merged[\"y_hat\"].fillna(0).values, index=X.index)\n\n        return preds.to_numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:58:28.161195Z","iopub.execute_input":"2025-07-05T10:58:28.161476Z","iopub.status.idle":"2025-07-05T10:58:28.169291Z","shell.execute_reply.started":"2025-07-05T10:58:28.161456Z","shell.execute_reply":"2025-07-05T10:58:28.168518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categorical = [\"Store\", \"Dept\", \"Type\", \"IsHoliday\"]\nnumerical = [\"Temperature\", \"Fuel_Price\", \"CPI\", \"Unemployment\",\n             \"MarkDown1\", \"MarkDown2\", \"MarkDown3\", \"MarkDown4\", \"MarkDown5\"]\nengineered = added_features\n\ncategorical_transformer = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\nnumerical_transformer = SimpleImputer(strategy=\"mean\")\n\npreprocessor = ColumnTransformerWithNames(\n    transformers=[\n        (\"num\", numerical_transformer, numerical + engineered),\n        (\"cat\", categorical_transformer, categorical),\n    ],\n    sparse_threshold=0.0\n)\n\npipeline = Pipeline([\n    (\"index_keeper\", MultiIndexKeeper()),\n    (\"date_features\", DateFeatureCreator()),\n    (\"preprocessor\", preprocessor),\n    (\"column_dropper\", ColumnDropper(columns=['Date', 'Store', 'Dept'])),\n    (\"patchtst\", TFTRegressor(epochs=25))\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T10:58:30.143306Z","iopub.execute_input":"2025-07-05T10:58:30.144037Z","iopub.status.idle":"2025-07-05T10:58:30.149358Z","shell.execute_reply.started":"2025-07-05T10:58:30.144011Z","shell.execute_reply":"2025-07-05T10:58:30.148560Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TRAIN_ON_ENTIRE_DATA = True\nprint(TRAIN_ON_ENTIRE_DATA)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T11:06:17.628232Z","iopub.execute_input":"2025-07-05T11:06:17.628964Z","iopub.status.idle":"2025-07-05T11:06:17.632900Z","shell.execute_reply.started":"2025-07-05T11:06:17.628939Z","shell.execute_reply":"2025-07-05T11:06:17.632184Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load and merge data\ndf_train = pd.read_csv(\"/kaggle/input/walmart-recruiting-store-sales-forecasting/train.csv.zip\", parse_dates=[\"Date\"])\ndf_features = pd.read_csv(\"/kaggle/input/walmart-recruiting-store-sales-forecasting/features.csv.zip\", parse_dates=[\"Date\"])\ndf_stores = pd.read_csv(\"/kaggle/input/walmart-recruiting-store-sales-forecasting/stores.csv\")\n\ndf = df_train.merge(df_features, on=[\"Store\", \"Date\", \"IsHoliday\"], how=\"left\")\ndf = df.merge(df_stores, on=\"Store\", how=\"left\")\ndf = df.sort_values(by=['Date', 'Store', 'Dept'])\n\nwith mlflow.start_run(run_name=\"Feature_Engineering\"):\n    mlflow.log_param(\"features_added\", added_features)\n\ny = df[\"Weekly_Sales\"]\nX = df.drop(columns=[\"Weekly_Sales\"])\n\nsplit_idx = int(len(X) * 0.8)\nX_train, X_val = X.iloc[:split_idx], X.iloc[split_idx:]\ny_train, y_val = y.iloc[:split_idx], y.iloc[split_idx:]\n\nif TRAIN_ON_ENTIRE_DATA:\n    X_train = X.copy()\n    y_train = y.copy()\n\n# print(X_train)\n# print(X_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T11:06:18.898244Z","iopub.execute_input":"2025-07-05T11:06:18.898823Z","iopub.status.idle":"2025-07-05T11:06:20.027975Z","shell.execute_reply.started":"2025-07-05T11:06:18.898801Z","shell.execute_reply":"2025-07-05T11:06:20.027377Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with mlflow.start_run(run_name=\"Training\"):\n    pipeline.fit(X_train, y_train)\n    best_model = pipeline\n\n    if not TRAIN_ON_ENTIRE_DATA:\n        preds = pipeline.predict(X_val)\n        mae = mean_absolute_error(y_val, preds)\n        weights = X_val[\"IsHoliday\"].apply(lambda x: 5 if x else 1)\n        wmae = (weights * np.abs(y_val - preds)).sum() / weights.sum()\n        mlflow.log_metric(\"MAE\", mae)\n        mlflow.log_metric(\"WMAE\", wmae)\n        # print(\"y:\\n\", y)\n        # print(\"preds:\\n\", preds)\n\n    model_path = \"model.pkl\"\n    joblib.dump(best_model, model_path)\n    mlflow.log_artifact(model_path)\n    \n    # mlflow.sklearn.log_model(best_model, artifact_path=\"model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T11:06:25.558318Z","iopub.execute_input":"2025-07-05T11:06:25.558870Z","iopub.status.idle":"2025-07-05T11:13:36.693158Z","shell.execute_reply.started":"2025-07-05T11:06:25.558838Z","shell.execute_reply":"2025-07-05T11:13:36.692453Z"}},"outputs":[],"execution_count":null}]}
